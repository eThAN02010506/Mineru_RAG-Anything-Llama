import os
import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from llama_cpp import Llama

def query(question, index_dir, top_k=3):
    """
    å®Œå…¨ç¦»çº¿çš„ RAG æŸ¥è¯¢ï¼Œè¿”å›æ¯”è¾ƒè¯¦ç»†çš„ç­”æ¡ˆ
    """
    # ç´¢å¼•ä¸æ˜ å°„æ–‡ä»¶è·¯å¾„
    faiss_index_path = os.path.join(index_dir, "faiss_index.index")
    mapping_path     = os.path.join(index_dir, "mapping.json")

    # æ¨¡å‹æ–‡ä»¶è·¯å¾„
    script_dir       = os.path.dirname(os.path.abspath(__file__))
    llama_model_path = os.path.join(script_dir, "models", "llama", "mistral-7b.gguf")
    embed_model_path = os.path.join(script_dir, "models", "all-MiniLM-L6-v2")

    # æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶
    for file_path in (faiss_index_path, mapping_path, llama_model_path, embed_model_path):
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"é”™è¯¯: å¿…éœ€æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")

    # åŠ è½½ embedding æ¨¡å‹
    print("æ­£åœ¨åŠ è½½ç¦»çº¿ embedding æ¨¡å‹...")
    embedder = SentenceTransformer(embed_model_path, device='cpu')

    # åŠ è½½ FAISS ç´¢å¼•å’Œæ–‡æœ¬ç‰‡æ®µ
    print("æ­£åœ¨åŠ è½½å‘é‡ç´¢å¼•å’Œæ–‡æœ¬ç‰‡æ®µæ˜ å°„...")
    index = faiss.read_index(faiss_index_path)
    with open(mapping_path, "r", encoding="utf-8") as f:
        chunks = json.load(f)
    print(f"ç´¢å¼•ä¿¡æ¯: {index.ntotal} ä¸ªå‘é‡, {len(chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µ")

    # ç”ŸæˆæŸ¥è¯¢å‘é‡å¹¶æœç´¢æœ€ç›¸å…³ç‰‡æ®µ
    print("æ­£åœ¨ç”ŸæˆæŸ¥è¯¢å‘é‡å¹¶æœç´¢æœ€ç›¸å…³ç‰‡æ®µ...")
    q_emb = embedder.encode([question], device='cpu').astype("float32")
    k = min(top_k, len(chunks), index.ntotal)
    distances, indices = index.search(q_emb, k=k)
    print(f"æ‰¾åˆ° {k} ä¸ªç›¸å…³ç‰‡æ®µï¼š")
    relevant_chunks = []
    for i, idx in enumerate(indices[0]):
        dist = float(distances[0][i])
        txt  = chunks[idx]
        print(f"  ç‰‡æ®µ{i+1}: è·ç¦» {dist:.4f}")
        relevant_chunks.append(txt)

    # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    context = "\n\n".join(f"[ç‰‡æ®µ{i+1}]\n{txt}"
                          for i, txt in enumerate(relevant_chunks))

    # â€”â€” æ”¹æˆâ€œè¯¦ç»†å›ç­”â€ Promptï¼Œå¹¶æŠ‘åˆ¶æ ‡é¢˜æ ¼å¼
    prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œè¯¦å°½å›ç­”ä¸‹é¢è¿™ä¸ªé—®é¢˜ï¼ˆæ— éœ€å†åŠ ä»»ä½•â€œ# å›ç­”â€è¿™æ ·çš„æ ‡é¢˜ï¼‰ï¼š
- å›ç­”ä¸­åº”åŒ…å«æ‰€æœ‰æ ¼å¼è¦æ±‚çš„ç»†èŠ‚
- ä¸¾ä¾‹è¯´æ˜å¦‚ä½•å‘½åã€å¦‚ä½•æäº¤ã€æ³¨æ„äº‹é¡¹ç­‰
- å¦‚æœå¯èƒ½ï¼Œç®€è¦è§£é‡Šä¸ºä»€ä¹ˆè¦è¿™æ ·åš

æ–‡æ¡£å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·ç»™å‡ºä¸€ä»½å®Œæ•´ã€è¯¦ç»†çš„å›ç­”ï¼š
"""

    # è°ƒè¯•ï¼šæ‰“å° Prompt
    print("ğŸ” PROMPT =====")
    print(prompt)
    print("ğŸ” END PROMPT =====")

    # è°ƒç”¨ LLaMA ç”Ÿæˆï¼Œå»æ‰ stop ä»¥è·å–å®Œæ•´æ­£æ–‡
    print("æ­£åœ¨åŠ è½½ç¦»çº¿ LLaMA æ¨¡å‹...")
    llm = Llama(
        model_path=llama_model_path,
        n_ctx=4096,
        n_threads=4,
        temperature=0.2,
        top_p=0.95,
        top_k=50,
        repeat_penalty=1.1,
        verbose=False,
    )

    print("æ­£åœ¨ç”Ÿæˆå›ç­”...")
    response = llm(
        prompt,
        max_tokens=256,
        echo=False
    )

    # è°ƒè¯•ï¼šæ‰“å°åŸå§‹è¿”å›ç»“æœ
    print("ğŸ” RAW RESPONSE =====")
    print(response)
    print("ğŸ” END RAW RESPONSE =====")

    # æå–å¹¶è¿”å›ç­”æ¡ˆï¼ŒåŠ ä¸Šæ¥æºä¿¡æ¯
    answer = response["choices"][0]["text"].strip()
    return f"{answer}\n\nå›ç­”åŸºäº {len(relevant_chunks)} ä¸ªæ–‡æ¡£ç‰‡æ®µ"

def interactive_query(index_dir):
    """
    äº¤äº’å¼æŸ¥è¯¢æ¨¡å¼
    """
    print("è¿›å…¥äº¤äº’å¼æ¨¡å¼ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºã€‚")
    while True:
        question = input("è¯·è¾“å…¥é—®é¢˜: ").strip()
        if question.lower() in ['quit', 'exit', 'q', 'é€€å‡º']:
            print("å†è§ï¼")
            break
        if not question:
            continue
        print("="*40)
        print("å›ç­”:\n" + query(question, index_dir))
        print("="*40)

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python query.py <index_dir> [é—®é¢˜]")
        sys.exit(1)
    idx_dir = sys.argv[1]
    if len(sys.argv) > 2:
        print("å›ç­”:\n" + query(" ".join(sys.argv[2:]), idx_dir))
    else:
        interactive_query(idx_dir)
